{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_filepath = './data/training.csv'\n",
    "train_data_raw = pd.read_csv(train_data_filepath, index_col='EventId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels_raw = train_data_raw['Label'].apply(lambda label: 1 if label == 's' else 0)\n",
    "train_weights_raw = train_data_raw['Weight']\n",
    "train_data_raw = train_data_raw.drop(['Label', 'Weight'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, hold_out_data, train_labels, hold_out_labels = cross_validation.train_test_split(train_data_raw, train_labels_raw,\n",
    "                                                                                            test_size=0.2, stratify=train_labels_raw,\n",
    "                                                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_filepath = './data/test.csv'\n",
    "test_data_raw = pd.read_csv(test_data_filepath, index_col='EventId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating classes for Higgs Boson data tranformation\n",
    "\n",
    "It is divided into modules, so that it is easy to carry out experiments with features like adding new ones, transforming etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import base, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MissingValuesTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        X_new = X.copy()\n",
    "        X_new.replace(-999.0, np.nan, inplace=True)\n",
    "        \n",
    "        for column in X_new.columns:\n",
    "            nan_ratio = len(X_new[X_new[column].isnull()]) / len(X_new)\n",
    "            if nan_ratio >= 0.5:\n",
    "                X_new.drop(column, axis=1, inplace=True)\n",
    "        self.lol=2\n",
    "        X_new.fillna(X_new.median(), inplace=True)\n",
    "\n",
    "        return X_new.values\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making AMS score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ams_score(y, y_pred, weights):\n",
    "    weights = weights.loc[y.index].copy().values\n",
    "    \n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    s = sum(weights * (y == 1) * (y_pred == 1))\n",
    "    b = sum(weights * (y == 0) * (y_pred == 1))\n",
    "    b_r = 10.0\n",
    "    \n",
    "    return np.sqrt(2 * ((s + b + b_r) * np.log(1 + s / (b + b_r))) - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, pipeline, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_regression = linear_model.LogisticRegression(random_state=42, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_regression_estimator = pipeline.Pipeline([\n",
    "    ('missing_values', MissingValuesTransformer()),\n",
    "    ('scale', preprocessing.StandardScaler()),\n",
    "    ('classifier', logistic_regression)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing optimal parameters by grid search and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation, grid_search, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logistic_regression_cv = cross_validation.KFold(len(train_labels), n_folds=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scale__with_std',\n",
       " 'classifier__dual',\n",
       " 'scale',\n",
       " 'classifier__max_iter',\n",
       " 'classifier__class_weight',\n",
       " 'classifier__tol',\n",
       " 'classifier__solver',\n",
       " 'classifier__multi_class',\n",
       " 'classifier__intercept_scaling',\n",
       " 'classifier__C',\n",
       " 'classifier__random_state',\n",
       " 'scale__with_mean',\n",
       " 'classifier__warm_start',\n",
       " 'steps',\n",
       " 'classifier__fit_intercept',\n",
       " 'classifier__n_jobs',\n",
       " 'classifier__penalty',\n",
       " 'scale__copy',\n",
       " 'classifier',\n",
       " 'classifier__verbose',\n",
       " 'missing_values']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_regression_estimator_grid_params = {\n",
    "    'classifier__C': [10 ** x for x in xrange(-1, 1 + 1)],\n",
    "#     'classifier__penalty': ['l1', 'l2'],\n",
    "#     'classifier__class_weight': [None, 'balanced'] # Will help with class inequality\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ams_score_with_train_weights(y, y_pred):\n",
    "    return ams_score(y, y_pred, train_weights)\n",
    "\n",
    "grid_cv = grid_search.GridSearchCV(logistic_regression_estimator, logistic_regression_estimator_grid_params,\n",
    "                                   scoring=metrics.make_scorer(ams_score_with_train_weights, greater_is_better=True),\n",
    "                                   cv=logistic_regression_cv,\n",
    "                                   n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   21.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=250000, n_folds=5, shuffle=True, random_state=42),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('missing_values', MissingValuesTransformer()), ('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=True, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'classifier__C': [0.1, 1, 10]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, scoring=make_scorer(ams_score_with_train_weights),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.47279266003\n",
      "{'classifier__C': 10}\n"
     ]
    }
   ],
   "source": [
    "print grid_cv.best_score_\n",
    "print grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 8.46732, std: 0.03708, params: {'classifier__C': 0.1},\n",
       " mean: 8.46970, std: 0.03708, params: {'classifier__C': 1},\n",
       " mean: 8.47032, std: 0.03715, params: {'classifier__C': 10}]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = grid_cv.best_estimator_.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_submission = pd.read_csv('./data/random_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>RankOrder</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>350000</td>\n",
       "      <td>416957</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350001</td>\n",
       "      <td>89624</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>350002</td>\n",
       "      <td>519845</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>350003</td>\n",
       "      <td>510885</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>350004</td>\n",
       "      <td>455944</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventId  RankOrder Class\n",
       "0   350000     416957     b\n",
       "1   350001      89624     b\n",
       "2   350002     519845     b\n",
       "3   350003     510885     s\n",
       "4   350004     455944     s"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EventId,RankOrder,Class\r\n",
      "350000,1,b\r\n",
      "350001,2,b\r\n",
      "350002,3,b\r\n",
      "350003,4,b\r\n",
      "350004,5,b\r\n",
      "350005,6,b\r\n",
      "350006,7,b\r\n",
      "350007,8,b\r\n",
      "350008,9,b\r\n"
     ]
    }
   ],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EventId,RankOrder,Class\r",
      "\r\n",
      "350000,416957,b\r",
      "\r\n",
      "350001,89624,b\r",
      "\r\n",
      "350002,519845,b\r",
      "\r\n",
      "350003,510885,s\r",
      "\r\n",
      "350004,455944,s\r",
      "\r\n",
      "350005,505711,b\r",
      "\r\n",
      "350006,108993,b\r",
      "\r\n",
      "350007,134597,b\r",
      "\r\n",
      "350008,194267,b\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head ./data/random_submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_boosting = ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_transformer = pipeline.Pipeline([\n",
    "    ('missing_values', MissingValuesTransformer()),\n",
    "    ('scale', preprocessing.StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_train_data = feature_transformer.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_boosting.fit(new_train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_test_data = feature_transformer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = gradient_boosting.predict(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_submission(preds, file_path):\n",
    "    submission_preds = map(lambda label: 's' if label == 1 else 'b', preds)\n",
    "    submission = pd.DataFrame({'EventId': test_data.index, \n",
    "                               'RankOrder': range(1, len(test_data) + 1), \n",
    "                               'Class': submission_preds\n",
    "                             })\n",
    "    submission = submission[['EventId', 'RankOrder', 'Class']] # Column reorder\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        submission.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_preds = map(lambda label: 's' if label == 1 else 'b', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'EventId': test_data.index, \n",
    "                           'RankOrder': range(1, len(test_data) + 1), \n",
    "                           'Class': submission_preds\n",
    "                          })\n",
    "submission = submission[['EventId', 'RankOrder', 'Class']] # Column reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550000"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
